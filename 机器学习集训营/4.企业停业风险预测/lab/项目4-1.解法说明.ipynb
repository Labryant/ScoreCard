{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解法说明\n",
    "\n",
    "本解法源自知乎文章讲解 - [CCF BDCI 企业经营退出风险预测](https://zhuanlan.zhihu.com/p/33662673)\n",
    "\n",
    "## 前言\n",
    "\n",
    "CCF 举办的这次大赛中这么多比赛，为什么唯独选择这个呢？\n",
    "\n",
    "1. 因为**门槛低**。我在参赛之前对所有的比赛有过大致的了解，其中比赛类型包括：自然语言处理（NLP）、计算机视觉（CV）和传统的数据挖掘比赛等等。作为一个第一次参赛的新人，我的重心不会放在需要一定的门槛的比赛，因此就排除了 NLP 和 CV 的比赛，再挑一个门槛最低的，那么目标就锁定了，于是我便将重心放在了企业经营退出风险预测这个比赛。\n",
    "2. 因为**有师兄带（提供 baseline，指导尝试方向）**。今年的 CCF 举办的大赛，我们实验室不少人参赛了，其中也包括不少往年拿过奖的师兄，他们有参赛经验。作为一只菜鸟，自然是希望有人能够给予少走弯路的建议。而师兄也建议新手参加这个方式相对简单的比赛作为入门。\n",
    "\n",
    "为什么我想要说一下这个呢，因为我相信未来有很多的新人会尝试加入数据挖掘的阵营中，他们也会遇到相同的境遇，我希望能够将我当时的一些思考与选择作为他们的参考选项，以便于他们做出他们的最优选择。\n",
    "\n",
    "## 代码框架\n",
    "\n",
    "第一次参赛，可以说连 Python 的语法都不熟悉，更何况 pandas 的各种操作。这时候师兄给的 baseline 就显得十分重要了。当中的各种基础操作，例如：文件读取、数据定义、分组聚集等等，对我来说都是新鲜的。其中最为关键的是**传统的数据挖掘比赛中的代码框架**。我们来看一下，这个极为经典的代码框架（非原始 baseline 框架，我做了一些修改）。\n",
    "\n",
    "```python\n",
    "# 1. 导入库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "...\n",
    "\n",
    "# 2. 读取数据文件\n",
    "train = pd.read_csv('../data/input/train.csv')\n",
    "test = pd.read_csv('../data/input/evaluation_public.csv')\n",
    "...\n",
    "\n",
    "# 3. 定义特征构建函数\n",
    "def get_entbase_feature(df):\n",
    "\t...\n",
    "def get_alter_feature(df):\n",
    "\t...\n",
    "...\n",
    "\n",
    "# 4. 调用函数，构建特征\n",
    "entbase_feat = get_entbase_feature(entbase)\n",
    "alter_feat = get_alter_feature(alter)\n",
    "...\n",
    "\n",
    "# 5. 拆分数据集的特征与标签\n",
    "dataset = pd.merge(entbase_feat, alter_feat, on='EID', how='left')\n",
    "...\n",
    "trainset = pd.merge(train, dataset, on='EID', how='left')\n",
    "testset = pd.merge(test, dataset, on='EID', how='left')\n",
    "train_feature = trainset.drop(['TARGET', 'ENDDATE'], axis=1)\n",
    "train_label = trainset.TARGET.values\n",
    "test_feature = testset\n",
    "test_index = testset.EID.values\n",
    "\n",
    "# 6. 模型的交叉验证\n",
    "...\n",
    "iterations, best_score = xgb_cv(train_feature, train_label, params, config['folds'], config['rounds'])\n",
    "...\n",
    "\n",
    "# 7. 模型的训练与预测\n",
    "...\n",
    "model, pred = xgb_predict(train_feature, train_label, test_feature, iterations, params)\n",
    "...\n",
    "\n",
    "# 8. 结果文件的写出\n",
    "res = store_result(test_index, pred, 0.18, '1207-xgb-%f(r%d)' % (best_score, iterations))\n",
    "```\n",
    "\n",
    "从上面给的样例代码中，我们可以观察到整个代码的框架如下：\n",
    "\n",
    "1. **导入库**\n",
    "2. **读取数据文件**\n",
    "3. **定义特征构建函数**\n",
    "4. **调用函数，构建特征**\n",
    "5. **拆分数据集的特征与标签**\n",
    "6. **模型的交叉验证**\n",
    "7. **模型的训练与预测**\n",
    "8. **结果文件的写出**\n",
    "\n",
    "使用这样一个代码框架，能够十分清晰的知道整个数据挖掘的流程，这一点对于第一次参赛的新人是尤为重要的。另外当我们想要提分时，我们只需要在特定的部分做出相应的修改就能够达到目的。例如：我希望构建新的特征，来提升我的分数，那么这时只需要新增框架中的第 3 和第 4 部分即可。\n",
    "\n",
    "## 数据预处理\n",
    "\n",
    "这个数据集中存在着不少的脏数据，这个阶段便是对这些脏数据进行处理，其中包括：\n",
    "\n",
    "1. 转化或者移除数据中存在的**中文字符**\n",
    "2. 针对性的**空值**填充\n",
    "3. 针对性地去除**重复值**\n",
    "4. **异常值**的处理（这点我没有做）\n",
    "\n",
    "## 特征\n",
    "\n",
    "我将特征分为 5 个部分，分别是**基础特征**、**偏离值特征**、**交叉特征**和**想象力特征**。\n",
    "\n",
    "### 基础特征\n",
    "\n",
    "基础特征是比赛中最容易想到的特征，其中包括：\n",
    "\n",
    "1. **保留字段**。数据集中某些关键字段直接保留成特征，例如：```uid```、```ZCZB```、```RGYEAR```、```INUM```、```ENUM``` 等\n",
    "2. **统计特征**。以某几个字段作为分组字段，然后进行统计操作，统计操作包括：计数、求和、最小值、最大值、最小最大差值、均值、标准差、比例等\n",
    "3. **特定集合中的统计特征**。先进行过滤，然后以某几个字段作为分组字段，然后进行统计操作。例如：统计近 1、2、5 年内的修改数额的最小值、最大值和均值等\n",
    "\n",
    "### 偏离值特征\n",
    "\n",
    "偏离值特征指**单个个体与分组之间的偏离距离**。以下的代码所生成的特征便是这一类特征：\n",
    "\n",
    "```python\n",
    "dataset['MPNUM_CLASS'] = dataset['INUM'].apply(lambda x : x if x <= 4 else 5)\n",
    "dataset['FSTINUM_CLASS'] = dataset['FSTINUM'].apply(lambda x : x if x <= 6 else 7)\n",
    "dataset.fillna(value={'alt_count': 0, 'rig_count': 0}, inplace=True)\n",
    "for column in ['MPNUM', 'INUM', 'FINZB', 'FSTINUM', 'TZINUM', 'ENUM', 'ZCZB', 'allnum', 'RGYEAR', 'alt_count', 'rig_count']:\n",
    "    groupby_list = [['HY'], ['ETYPE'], ['HY', 'ETYPE'], ['HY', 'PROV'], ['ETYPE', 'PROV'], ['MPNUM_CLASS'], ['FSTINUM_CLASS']]\n",
    "    for groupby in groupby_list:\n",
    "        if 'MPNUM_CLASS' in groupby and column == 'MPNUM':\n",
    "            continue\n",
    "        if 'FSTINUM_CLASS' in groupby and column == 'FSTINUM':\n",
    "            continue\n",
    "        groupby_keylist = []\n",
    "        for key in groupby:\n",
    "            groupby_keylist.append(dataset[key])\n",
    "        tmp = dataset[column].groupby(groupby_keylist).agg([sum, min, max, np.mean]).reset_index()\n",
    "        tmp = pd.merge(dataset, tmp, on=groupby, how='left')\n",
    "        dataset['ent_' + column.lower() + '-mean_gb_' + '_'.join(groupby).lower()] = dataset[column] - tmp['mean']\n",
    "        dataset['ent_' + column.lower() + '-min_gb_' + '_'.join(groupby).lower()] = dataset[column] - tmp['min']\n",
    "        dataset['ent_' + column.lower() + '-max_gb_' + '_'.join(groupby).lower()] = dataset[column] - tmp['max']\n",
    "        dataset['ent_' + column.lower() + '/sum_gb_' + '_'.join(groupby).lower()] = dataset[column] / tmp['sum']\n",
    "dataset.drop(['MPNUM_CLASS', 'FSTINUM_CLASS'], axis=1, inplace=True)\n",
    "```\n",
    "\n",
    "这段代码的意思是：\n",
    "\n",
    "1. 首先，根据分组字段对数据集进行分组\n",
    "2. 然后计算每个个体与分组的均值、最小值、最大值和求和值之间的偏离距离\n",
    "\n",
    "这类特征对于这个比赛十分有效，是我分数大幅上升的一个原因。\n",
    "\n",
    "### 交叉特征\n",
    "\n",
    "交叉特征指**不单单从一个角度去构建特征，而从多个角度构建够特征**，或者说**将特征之间相互作用后生成新的特征**。这类特征包括：\n",
    "\n",
    "1. **加减乘除特征**。将特征与特征做加减乘除操作，也就是所谓的暴力出奇迹。例如：```MPNUM+INUM```、```FINZB/ZCZB``` 等\n",
    "2. **独热交叉特征**。将一些特征做独热编码后，然后乘以某个特征。例如：将 ```HY``` 做独热编码后，乘以 ```ZCZB```、```RGYEAR``` 等\n",
    "3. **多项式交叉特征**。对特征做多项式组合。例如：```MPNUM^2+INUM``` 等（我没有做这类交叉特征）\n",
    "\n",
    "交叉特征的效果也十分明显，能显著的提升分数，其中独热交叉特征在这个比赛中最为有效。\n",
    "\n",
    "### 想象力特征\n",
    "\n",
    "想象力特征这个词是我自己构造的，指的是根据实际的业务场景，思考其中可能存在的一些隐晦的特征。例如：投资表中，就可以构建一个投资网络，然后基于这个网络提取相关的特征。这个思路来自我的师兄 @Kaho，这也是我赛后才了解到的特征构造方式，十分新颖。\n",
    "\n",
    "## 模型\n",
    "\n",
    "模型部分包括：**单模型的提分**与**多模型融合**。\n",
    "\n",
    "首先，谈谈单模型的提分。在这个比赛中，根据师兄的建议，我选择了 XGBoost，使用它的原因在于：\n",
    "\n",
    "1. 树模型有较强的可解释性，往往简单且高效\n",
    "2. 树模型对于异常值有较强的鲁棒性\n",
    "3. 树模型对特征处理的要求比较低，不需要对特征进行归一化与空值填充\n",
    "\n",
    "其次，是多模型融合。这部分是我的另一位队友做的，因此我没有过多的尝试多模型融合。在这个比赛中，我们团队的融合效果不是太好，加权融合之后分数仅提升 1 至 2 个千。\n",
    "\n",
    "## 踩过的坑\n",
    "\n",
    "新人入赛不踩坑是不可能的，比赛中我是踩了无数个坑，其中比较有意思的，比较隐晦的有这么几个：\n",
    "\n",
    "1. **不要带着刻板印象去筛选特征**，换句话说，你不要觉得其他比赛没用的特征对于这个比赛同样没用。在这个比赛中，ID 特征是一个强特征，我刚开始就带着刻板印象把它删了，导致 3 个千分点的劣势，发现这个问题也耗费了不少时间\n",
    "2. **在对 dataframe 排序之后一定要 调用 ```reset_index(drop=True)```**，不然之后对这个 dataframe 的各种操作的是误操作。这个坑同样耗费了我不少的精力\n",
    "3. **不要太早就开始模型调参**，模型调参只能带来极少的提升，在你的分数没有达到一定竞争力的时候，调参带来的收益是极少的，因此在调参这个举动的价值在比赛早期是较低的\n",
    "4. 复赛开始后，**初赛数据别果断抛弃**，应该试一试效果，辩证式的采纳\n",
    "\n",
    "## 可以尝试的点\n",
    "\n",
    "1. 没尝试**融合大法**。因为团队中有队员负责融合，所以在比赛中我没有尝试融合大法，这点比较可惜。另外我们团队的融合策略是 blending（加权融合），还可以尝试的策略包括：stacking、bagging 等\n",
    "2. 没尝试使用**初赛的数据**。这点输在新人没经验，根本没有意识到可以使用初赛的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
